Домашняя контрольная работа №3
Задание
Реализовать программу обнаружения объектов в видеопотоке на основе нейронной сети.
Теоретические сведения
Теоретические сведения по теме лабораторной работы можно найти в ЭУМД_4, ЭУМД_5, а также в официальной документации:
•	TensorFlow Object Detection API
•	OpenCV documentation for video processing
•	YOLO (You Only Look Once) architecture overview
Порядок выполнения работы
1. Подготовка видеоданных
a. Составить базу видеоклипов для обучения:
•	Минимум 100-200 видеоклипов длительностью 5-30 секунд каждый
•	Видео должно содержать объекты целевых классов в различных позициях и масштабах
•	Разнообразить сцены: различные освещение, фоны, окклюзии
b. Разбить видеоданные на три множества:
•	Обучающее (train): 60-70% видеоклипов
•	Валидационное (validation): 15-20% видеоклипов
•	Тестовое (test): 15-20% видеоклипов
2. Подготовка аннотаций и извлечение фреймов
a. Произвести разметку видеоклипов:
•	Для каждого видеоклипа выбрать ключевые фреймы или извлечь фреймы с интервалом N кадров
•	Аннотировать объекты в формате PASCAL VOC XML, COCO JSON или YOLO TXT
•	Аннотация должна включать: класс объекта, координаты bounding box (x, y, width, height)
b. Подготовить структуру данных:
•	Извлечь фреймы из видеоклипов (примерно 5-10 фреймов на видео или на основе detector)
•	Сохранить фреймы с соответствующей разметкой
•	Убедиться в качестве аннотаций (отсутствие пропусков, корректность координат)
c. Применить аугментацию данных:
•	Горизонтальное и вертикальное отражение
•	Случайная обрезка (crop)
•	Изменение яркости и контраста
•	Добавление шума
•	Небольшое масштабирование объектов
3. Конструирование, обучение и оценка качества модели обнаружения
a. Выбрать архитектуру модели обнаружения:
•	Вариант А (Рекомендуется): Создание собственной архитектуры на базе Feature Pyramid Networks (FPN)
•	Вариант Б: Transfer Learning с использованием предобученных моделей (Faster R-CNN, RetinaNet, SSD, EfficientDet)
•	Отметим: использование YOLO разрешено как альтернатива, но требует дополнительного обоснования
b. Выбрать компоненты модели:
•	Backbone сеть (ResNet50, EfficientNet, MobileNet)
•	Region Proposal Network (RPN) или аналог
•	Head сеть для классификации и регрессии bounding box
c. Выбрать функции потерь для обнаружения:
•	Softmax Cross-Entropy для классификации
•	Smooth L1 Loss или L2 Loss для регрессии bounding box координат
d. Оптимизировать архитектуру:
•	Использовать валидационное множество для подбора гиперпараметров
•	Контролировать метрики: mAP (mean Average Precision), precision, recall
•	При необходимости применить техники regularization
e. Остановиться на варианте модели с лучшей обобщающей способностью
4. Обработка видеопотока и постобработка
a. Реализовать обработку видеопотока:
•	Загрузить видеофайл или подключиться к веб-камере
•	Проводить инференс на каждом фрейме или на фреймах с интервалом
•	Обрабатывать предсказания модели
b. Применить постобработку:
•	Non-Maximum Suppression (NMS) для удаления дублирующихся боксов
•	Фильтрацию по уверенности (confidence threshold)
•	Сглаживание траекторий объектов между фреймами (опционально)
c. Визуализация результатов:
•	Рисовать bounding box'ы с метками классов на видеопотоке
•	Добавить информацию о confidence score каждого обнаружения
•	Добавить счетчики обнаруженных объектов по классам
5. Использование и диагностика
a. Провести тестирование на реальных видеоклипах:
•	Оценить корректность обнаружений
•	Проверить, обнаруживаются ли объекты всех классов
•	Проанализировать ошибки (false positives, false negatives)
b. Провести анализ производительности:
•	Вычислить fps (frames per second) при инференсе
•	Оценить использование памяти и CPU/GPU
•	Определить узкие места в обработке
c. При необходимости оптимизировать:
•	Применить квантизацию модели
•	Использовать model pruning
•	Оптимизировать обработку видеопотока
•	Вернуться на этап 2 при низких результатах обнаружения
